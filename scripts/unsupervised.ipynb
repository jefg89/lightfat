{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from os import read\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import seaborn as sns\n",
    "import time \n",
    "# from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "# from tsfresh.utilities.dataframe_functions import impute\n",
    "# from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "# from tsfresh.feature_selection.relevance import calculate_relevance_table\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "\n",
    "def checkNotEmpty(input_array):\n",
    "    for x in input_array:\n",
    "        if float(x) > 0:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def getAverage(input_array):\n",
    "    acc = 0.0\n",
    "    for x in input_array:\n",
    "        acc+=x\n",
    "    return acc / len(input_array)\n",
    "\n",
    "def getWindowFrameFromDir(source_dir, window_size, verdict):\n",
    "    valid = 0\n",
    "    cache_windows = []\n",
    "    ipc_windows = []\n",
    "    ver_windows = []\n",
    "    for subdir, dirs, files in os.walk(source_dir):\n",
    "        for dir in dirs:\n",
    "            cache = []\n",
    "            ipc = []\n",
    "            ipc_window = []\n",
    "            cache_window= []\n",
    "            for filename in os.listdir(os.path.join(subdir, dir)):\n",
    "                f = os.path.join(subdir, dir, filename)\n",
    "                actualfile = open(f,'r')\n",
    "                if (filename[:3] == \"ipc\"):\n",
    "                    ipc = actualfile.readlines()\n",
    "                else:\n",
    "                    cache = actualfile.readlines()\n",
    "            dipc = window_size-len(ipc)\n",
    "            dcache = window_size-len(cache)\n",
    "            if (checkNotEmpty(cache) and checkNotEmpty(ipc)):\n",
    "                for x in range(0, len(ipc)):\n",
    "                    ipc_window.append(float(ipc[x]))\n",
    "                for x in range(0, len(cache)):\n",
    "                    # let's normalize cache access to IPC\n",
    "                    cache_window.append(float(cache[x])/1000000)\n",
    "                start = time.time_ns()\n",
    "                cache_windows.append(getAverage(cache_window))\n",
    "                ipc_windows.append(getAverage(ipc_window))\n",
    "                if verdict:\n",
    "                    ver_windows.append(1)\n",
    "                end = time.time_ns()\n",
    "                #print(\"Average time = \" + str((end-start) /1000))\n",
    "                valid += 1\n",
    "    print(\"Total windows = \" + str(valid))\n",
    "    if verdict:\n",
    "        dataframe = pd.DataFrame(list(zip(ipc_windows, cache_windows, ver_windows)), columns=['avg_ipc', 'avg_cache', 'verdict'])\n",
    "    else:\n",
    "        dataframe = pd.DataFrame(list(zip(ipc_windows, cache_windows)), columns=['avg_ipc', 'avg_cache'])\n",
    "    return dataframe\n",
    "\n",
    "def getWindowFrameFromDirAttack(source_dir, window_size, verdict):\n",
    "    valid = 0\n",
    "    cache_windows = []\n",
    "    ipc_windows = []\n",
    "    ver_windows = []\n",
    "    for subdir, dirs, files in os.walk(source_dir):\n",
    "        for dir in dirs:\n",
    "            cache = []\n",
    "            ipc = []\n",
    "            ipc_window = []\n",
    "            cache_window= []\n",
    "            for filename in os.listdir(os.path.join(subdir, dir)):\n",
    "                f = os.path.join(subdir, dir, filename)\n",
    "                actualfile = open(f,'r')\n",
    "                if (filename[:3] == \"ipc\"):\n",
    "                    ipc = actualfile.readlines()\n",
    "                else:\n",
    "                    cache = actualfile.readlines()\n",
    "            dipc = window_size-len(ipc)\n",
    "            dcache = window_size-len(cache)\n",
    "            if dipc > 0:\n",
    "                for x in range(dipc):\n",
    "                    ipc.append('0')\n",
    "            if dcache > 0:\n",
    "                for x in range(dcache):\n",
    "                    cache.append('0')\n",
    "            if (checkNotEmpty(cache) and checkNotEmpty(ipc)):\n",
    "                for x in range(0, len(ipc)):\n",
    "                    ipc_window.append(float(ipc[x]))\n",
    "                for x in range(0, len(cache)):\n",
    "                    # let's normalize cache access to IPC\n",
    "                    cache_window.append(float(cache[x])/1000000)\n",
    "                cache_windows.append(getAverage(cache_window))\n",
    "                ipc_windows.append(getAverage(ipc_window))\n",
    "                if verdict:\n",
    "                    ver_windows.append(0)\n",
    "                valid += 1\n",
    "    print(\"Total windows attack/bechmarks = \" + str(valid))\n",
    "    if verdict:\n",
    "        dataframe = pd.DataFrame(list(zip(ipc_windows, cache_windows, ver_windows)), columns=['avg_ipc', 'avg_cache', 'verdict'])\n",
    "    else:\n",
    "        dataframe = pd.DataFrame(list(zip(ipc_windows, cache_windows)), columns=['avg_ipc', 'avg_cache']) \n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def create_reference(df, label):\n",
    "    data = []\n",
    "    for x in df.index:\n",
    "        data.append(label)\n",
    "    return data\n",
    "\n",
    "def false_negative_rate(reference, prediction):\n",
    "  false_negatives = 0\n",
    "  true_positives = 0\n",
    "  \n",
    "  for i in range(len(reference)):\n",
    "    if reference[i] == -1 and prediction[i] == 1:\n",
    "      false_negatives += 1\n",
    "    if reference[i] == -1:\n",
    "      true_positives += 1\n",
    "      \n",
    "  false_negative_rate = false_negatives / (true_positives)\n",
    "  print(\"False negatives = \" + str(false_negatives))\n",
    "  print (\"Total positives =  \" + str(true_positives))\n",
    "  return false_negative_rate\n",
    "\n",
    "def false_positive_rate(reference, prediction):\n",
    "  #false negatives / positives\n",
    "  false_positives = 0\n",
    "  true_negatives = 0\n",
    "  \n",
    "  for i in range(len(reference)):\n",
    "    if reference[i] == 1 and prediction[i] == -1:\n",
    "      false_positives += 1\n",
    "    if reference[i] == 1:\n",
    "      true_negatives += 1\n",
    "      \n",
    "  false_positive_rate = false_positives / (true_negatives)\n",
    "  print(\"False positives = \" + str(false_positives))\n",
    "  print(\"Total negatives = \" + str(true_negatives))\n",
    "  return false_positive_rate\n",
    "\n",
    "\n",
    "def accuracy(reference, prediction):\n",
    "    total = len(prediction) + 1\n",
    "    matches = 0\n",
    "    for i in range(total - 1):\n",
    "        if reference[i] == prediction[i]:\n",
    "            matches += 1\n",
    "    return matches/total\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data frame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = 'tinyexr'\n",
    "#bench = '../results/benchmarks/'\n",
    "\n",
    "target = 'notbench/allbench/fmm'\n",
    "bench = \"../results/notbench/notfmm/\" # change me if necessary\n",
    "\n",
    "normal = \"../results/\" + target  +\"/normal/\"\n",
    "attack = \"../results/\" + target  +\"/attack/\"\n",
    "#window_size = 50  #change me if necessary: 10 for custom, 50 for tiny and pdf\n",
    "window_size = 300 # 300  radiosity, raytrace 300 (works), fmm(kinda), watern(play with wsize and sampling), barnes (crashes, discard possibles crashes)\n",
    "verdict = False\n",
    "\n",
    "df_normal = getWindowFrameFromDir(normal,window_size, verdict)\n",
    "df_attack = getWindowFrameFromDirAttack(attack,window_size, verdict)\n",
    "print(\"Bench: \")\n",
    "df_bench  = getWindowFrameFromDirAttack(bench,window_size, verdict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_bench  = getCompleteWindowFrameFromDirAttack(bench,window_size)\n",
    "#df_normal = getCompleteWindowFrameFromDir(normal,window_size)\n",
    "#df_attack = getCompleteWindowFrameFromDirAttack(attack,window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_count =  len(df_normal.index) - len(df_attack.index)\n",
    "full_df = pd.concat([df_normal, df_attack],ignore_index=True)\n",
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ar = full_df.to_numpy()\n",
    "\n",
    "# hh = len(full_df.index)\n",
    "# dim = 3\n",
    "\n",
    "# w, h, l = dim, hh*window_size, window_size\n",
    "# Matrix = [[0 for x in range(w)] for y in range(h)] \n",
    "\n",
    "# for int3 in range(h):\n",
    "#   Matrix[int3][0] = (int3//l)\n",
    "#   Matrix[int3][1] = ar[math.floor(int3//l)][int3%l]\n",
    "#   Matrix[int3][2] = ar[math.floor(int3//l)][(int3%l)+l]\n",
    "\n",
    "\n",
    "\n",
    "# #tags = []\n",
    "# #for x in range (0, hh):\n",
    "# #    tags.append(x)\n",
    "\n",
    "# df = pd.DataFrame(Matrix, columns =['Tag', 'ipc', 'cache'])\n",
    "# #df = pd.DataFrame(Matrix, columns =['Tag', 'cache'])\n",
    "if (verdict):\n",
    "    X = full_df.loc[:, full_df.columns!=\"verdict\"]\n",
    "    y = full_df[\"verdict\"]\n",
    "    y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_new = mutual_info_classif(X,y)\n",
    "#X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#extraction_settings = ComprehensiveFCParameters()\n",
    "#data_filtered = extract_relevant_features(df, y, column_id='Tag', default_fc_parameters=extraction_settings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter = 1 #change for time measurement\n",
    "#import seaborn as sns\n",
    "#sns.histplot(df_attack['avg_cache'], kde=True, stat='probability')\n",
    "#sns.histplot(df_attack['avg_ipc'], kde=True, stat='probability')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing normal and attack traces to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = False\n",
    "if (log):\n",
    "    with open('../results/paper/normal', 'w') as f:\n",
    "        dfAsString = np.log10(df_normal*1000000).to_string(header=True, index=False)\n",
    "        f.write(dfAsString)\n",
    "\n",
    "    with open('../results/paper/attack', 'w') as f:\n",
    "        dfAsString = np.log10(df_attack*1000000).to_string(header=True, index=False)\n",
    "        f.write(dfAsString)\n",
    "else:\n",
    "    with open('../results/paper/normal', 'w') as f:\n",
    "        dfAsString = df_normal.to_string(header=True, index=False)\n",
    "        f.write(dfAsString)\n",
    "\n",
    "    with open('../results/paper/attack', 'w') as f:\n",
    "        dfAsString = df_attack.to_string(header=True, index=False)\n",
    "        f.write(dfAsString)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised stuff"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset visualization (normal data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.concat([df_normal], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_a_axis = df_attack[\"avg_ipc\"]\n",
    "y_a_axis = df_attack[\"avg_cache\"]    \n",
    "\n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range(len(df_normal.index)):\n",
    "    x_norm.append(x_axis[i])\n",
    "    y_norm.append(y_axis[i])\n",
    "for i in range(len(df_attack.index)):\n",
    "    x_anorm.append(x_a_axis[i])\n",
    "    y_anorm.append(y_a_axis[i])\n",
    "\n",
    "# Plotting\n",
    "#plt.xlim(0,0.25) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "c1 = plt.scatter( x_norm,y_norm, c='green', s = 1)\n",
    "c2 = plt.scatter( x_anorm, y_anorm, c='magenta', s = 1)\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "\n",
    "\n",
    "\n",
    "#plt.scatter(y_axis, x_axis)\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-class SVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O(n^2) complexity one-class support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_eval = train_test_split(df_normal, shuffle = True,test_size=0.5)\n",
    "\n",
    "\n",
    "clf = OneClassSVM(gamma='scale', kernel='rbf', nu=0.06).fit(X_train) #0.07\n",
    "#TODO: explore nu value https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html#sklearn.svm.OneClassSVM.decision_function\n",
    "Y_pred_attack = clf.predict(df_attack)\n",
    "Y_pred_normal = clf.predict(X_eval)\n",
    "\n",
    "start = time.time_ns()\n",
    "dif = 0\n",
    "for x in range(iter):\n",
    "    start = time.time_ns()\n",
    "    Y_pred_bench = clf.predict(df_bench)\n",
    "    end = time.time_ns()\n",
    "    dif += end - start\n",
    "print(\"Time OSVM = \" + str(dif/(iter*1000*len(Y_pred_bench))) + \"us\")\n",
    "\n",
    "y_train_normal = create_reference(X_eval, 1)\n",
    "y_train_attack = create_reference(df_attack, -1)\n",
    "y_train_bench = create_reference(df_bench, -1)\n",
    "\n",
    "#print(len(y_train_attack))\n",
    "\n",
    "y_train = np.concatenate([y_train_normal, y_train_attack]) #y_train_bench y_train_attack\n",
    "y_pred = np.concatenate([Y_pred_normal, Y_pred_attack]) #Y_pred_bench, Y_pred_attack\n",
    "df_merged =  pd.concat([X_eval, df_attack, df_bench], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "\n",
    "sc_osvm =  round(accuracy(y_train, y_pred)*100,2)\n",
    "fn_osvm  = round(false_negative_rate(y_train, y_pred)*100,2)\n",
    "print(\"[Full set] Accuracy = \", sc_osvm , \"\\t\", round(false_positive_rate(y_train, y_pred)*100,2), \"\\t\", fn_osvm)\n",
    "\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green', s =1)\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta', s =1)\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "#plt.xlim(0,0.3) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "plt.title(target +\"  predictions One-Class SVM\")\n",
    "plt.show()\n",
    "#plt.plot(y_train, c = 'magenta',  linestyle = 'None', marker='*')\n",
    "#plt.plot(y_pred, c= 'cyan', linestyle='None', marker='3')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD-OSVM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear(-complexity) approximation to guassian-kernel One-Class SVM using Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "X_train, X_eval = train_test_split(df_normal, shuffle = True,test_size=0.5)\n",
    "clf = linear_model.SGDOneClassSVM( nu=0.07)\n",
    "\n",
    "clf.fit(X_train)\n",
    "\n",
    "Y_pred_attack = clf.predict(df_attack)\n",
    "Y_pred_normal = clf.predict(X_eval)\n",
    "Y_pred_bench = clf.predict(df_bench)\n",
    "\n",
    "y_train_normal = create_reference(X_eval, 1)\n",
    "y_train_attack = create_reference(df_attack, -1)\n",
    "y_train_bench = create_reference(df_bench, -1)\n",
    "\n",
    "\n",
    "y_train = np.concatenate([y_train_normal, y_train_attack, y_train_bench])\n",
    "y_pred = np.concatenate([Y_pred_normal, Y_pred_attack, Y_pred_bench])\n",
    "df_merged =  pd.concat([X_eval, df_attack, df_bench], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "sc_sgd =  round(accuracy(y_train, y_pred)*100,2)\n",
    "fn_sgd = round(false_negative_rate(y_train, y_pred)*100,2)\n",
    "print(\"[Full set] Accuracy = \", sc_sgd , \"\\t\", round(false_positive_rate(y_train, y_pred)*100,2), \"\\t\", fn_sgd , \"%\")\n",
    "\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green')\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta')\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "#plt.xlim(0,1) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "plt.title(target +\" predictions Stochastic Gradient Descend OSVM\")\n",
    "plt.show()\n",
    "#plt.plot(y_train, c = 'magenta',  linestyle = 'None', marker='*')\n",
    "#plt.plot(y_pred, c= 'cyan', linestyle='None', marker='3')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local outlier factor (LOF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "X_train, X_eval = train_test_split(df_normal, shuffle = True,test_size=0.5)\n",
    "\n",
    "lof = LocalOutlierFactor(novelty=True,n_neighbors=15) # change n_neighbors\n",
    "lof.fit(X_train.values)\n",
    "\n",
    "Y_pred_attack = lof.predict(df_attack)\n",
    "Y_pred_normal = lof.predict(X_eval)\n",
    "dif = 0\n",
    "for x in range(iter):\n",
    "    start = time.time_ns()\n",
    "    Y_pred_bench = lof.predict(df_bench)\n",
    "    end = time.time_ns()\n",
    "    dif += end - start\n",
    "print(\"Time LOF = \" + str(dif/(iter*1000*len(Y_pred_bench))) + \"us\")\n",
    "\n",
    "\n",
    "y_train_normal = create_reference(X_eval, 1)\n",
    "y_train_attack = create_reference(df_attack, -1)\n",
    "y_train_bench = create_reference(df_bench, -1)\n",
    "\n",
    "\n",
    "y_train = np.concatenate([y_train_normal, y_train_attack])  #y_train_bench y_train_attack\n",
    "y_pred = np.concatenate([Y_pred_normal, Y_pred_attack])  #Y_pred_bench, Y_pred_attack\n",
    "df_merged =  pd.concat([X_eval, df_attack, df_bench], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "sc_lof = round(accuracy(y_train, y_pred)*100,2)\n",
    "fn_lof = round(false_negative_rate(y_train, y_pred)*100,2)\n",
    "print(\"[Full set] Accuracy = \",sc_lof , \"\\t\", round(false_positive_rate(y_train, y_pred)*100,2), \"\\t\", fn_lof)\n",
    "\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green')\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta')\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "#plt.xlim(0,1) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "plt.title(target +\"  predictions Local Outlier Factor\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection (w synthetic anormalities )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic anomaly generation\n",
    "X_train, X_eval = train_test_split(df_normal, shuffle = True,test_size=0.5)\n",
    "anomaly_ratio = 0.1 #\n",
    "\n",
    "std = X_train.std()\n",
    "avg = X_train.mean()\n",
    "max = X_train.max()\n",
    "min = X_train.min()\n",
    "scac = []\n",
    "sipc = []\n",
    "\n",
    "\n",
    "#Separating the feature are in  4 regions, excluding the normal area data\n",
    "for i in range(int(len(X_train.values) * anomaly_ratio)//4):\n",
    "    scac.append(random.uniform(0, avg[\"avg_cache\"]+5*std[\"avg_cache\"]))\n",
    "    sipc.append(random.uniform(0, min[\"avg_ipc\"]))\n",
    "    scac.append(random.uniform(0, avg[\"avg_cache\"]+5*std[\"avg_cache\"]))\n",
    "    sipc.append(random.uniform(max[\"avg_ipc\"], avg[\"avg_ipc\"]+5*std[\"avg_ipc\"]))\n",
    "    scac.append(random.uniform(0, min[\"avg_cache\"]))\n",
    "    sipc.append(random.uniform(0,  avg[\"avg_ipc\"]+5*std[\"avg_ipc\"]))\n",
    "    scac.append(random.uniform(max[\"avg_cache\"], avg[\"avg_cache\"]+5*std[\"avg_cache\"]))\n",
    "    sipc.append(random.uniform(0, avg[\"avg_ipc\"]+5*std[\"avg_ipc\"]))\n",
    "\n",
    "df_synth = pd.DataFrame(list(zip(sipc,scac)), columns=['avg_ipc', 'avg_cache'])\n",
    "\n",
    "\n",
    "X_train_merged = pd.concat([df_synth, X_train], ignore_index = True)\n",
    "X_train_merged\n",
    "\n",
    "x_axis = X_train_merged[\"avg_ipc\"]  \n",
    "y_axis = X_train_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(X_train_merged)):\n",
    "    if i >= len(df_synth.values):\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green')\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta')\n",
    "plt.legend([c1, c2], ['normal', '(synth) abnormal'])\n",
    "#plt.xlim(0,1) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.title(\"Normal and synthetic data distribution\")\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_merged"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elliptic envelop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "\n",
    "\n",
    "cov = EllipticEnvelope(contamination=anomaly_ratio).fit(X_train_merged)\n",
    "\n",
    "Y_pred_attack = cov.predict(df_attack)\n",
    "Y_pred_normal = cov.predict(X_eval)\n",
    "Y_pred_bench = cov.predict(df_bench)\n",
    "\n",
    "\n",
    "y_train_normal = create_reference(X_eval, 1)\n",
    "y_train_attack = create_reference(df_attack, -1)\n",
    "y_train_bench = create_reference(df_bench, -1)\n",
    "\n",
    "\n",
    "y_train = np.concatenate([y_train_normal, y_train_attack, y_train_bench])\n",
    "y_pred = np.concatenate([Y_pred_normal, Y_pred_attack, Y_pred_bench])\n",
    "df_merged =  pd.concat([X_eval, df_attack, df_bench], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "sc_env = round(accuracy(y_train, y_pred)*100,2)\n",
    "fn_env = round(false_negative_rate(y_train, y_pred)*100,2)\n",
    "print(\"[Full set] Accuracy = \",sc_env , \"%, fp = \", round(false_positive_rate(y_train, y_pred)*100,2), \"%, fn = \", fn_env , \"%\")\n",
    "\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green')\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta')\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "#plt.xlim(0,1) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "plt.title(target +\"  predictions Elliptic Envelop\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(n_estimators=15)\n",
    "clf.fit(X_train_merged)\n",
    "Y_pred_attack = clf.predict(df_attack)\n",
    "Y_pred_normal = clf.predict(X_eval)\n",
    "dif = 0\n",
    "for x in range(iter):\n",
    "    start = time.time_ns()\n",
    "    Y_pred_bench = clf.predict(df_bench)\n",
    "    end = time.time_ns()\n",
    "    dif += end - start\n",
    "print(\"Time Isolation = \" + str(dif/(iter*1000*len(Y_pred_bench))) + \"us\")\n",
    "\n",
    "\n",
    "y_train_normal = create_reference(X_eval, 1)\n",
    "y_train_attack = create_reference(df_attack, -1)\n",
    "y_train_bench = create_reference(df_bench, -1)\n",
    "\n",
    "\n",
    "y_train = np.concatenate([y_train_normal, y_train_attack]) #y_train_bench y_train_attack\n",
    "y_pred = np.concatenate([Y_pred_normal, Y_pred_attack])#Y_pred_bench, Y_pred_attack\n",
    "df_merged =  pd.concat([X_eval, df_attack, df_bench], ignore_index=True)\n",
    "x_axis = df_merged[\"avg_ipc\"]  \n",
    "y_axis = df_merged[\"avg_cache\"]  \n",
    "\n",
    "x_norm, x_anorm, y_norm, y_anorm = [], [], [], []\n",
    "for i in range (len(y_pred)):\n",
    "    if y_pred[i] == 1:\n",
    "        x_norm.append(x_axis[i])\n",
    "        y_norm.append(y_axis[i])\n",
    "    else:\n",
    "        x_anorm.append(x_axis[i])\n",
    "        y_anorm.append(y_axis[i])\n",
    "sc_iso = round(accuracy(y_train, y_pred)*100,2)\n",
    "fn_iso = round(false_negative_rate(y_train, y_pred)*100,2)\n",
    "print(\"[Full set] Accuracy = \",sc_iso , \"\\t\", round(false_positive_rate(y_train, y_pred)*100,2), \"\\t\",fn_iso )\n",
    "\n",
    "# # Plotting\n",
    "c1 = plt.scatter(y_norm, x_norm, c='green')\n",
    "c2 = plt.scatter(y_anorm, x_anorm, c='magenta')\n",
    "plt.legend([c1, c2], ['normal', 'abnormal'])\n",
    "#plt.xlim(0,1) #nolimit for tinyexr\n",
    "#plt.ylim(0,1) #2.5 for tinyexr, 1 for pcf2bdf\n",
    "plt.xlabel(\"IPC\")\n",
    "plt.ylabel(\"Cache accesses (x10^6)\")\n",
    "plt.title(target +\"  predictions\")\n",
    "plt.show()\n",
    "print (len(Y_pred_attack))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "          sc_osvm,\n",
    "          sc_sgd,\n",
    "          sc_lof,\n",
    "          sc_env,\n",
    "          sc_iso\n",
    "          ]\n",
    "\n",
    "algorithms = [\n",
    "              \"One-Class SVM\",\n",
    "              \"SGD SVM\",\n",
    "              \"Local Outlier Factor\",\n",
    "              \"Elliptic Envelop\",\n",
    "              \"IsolationForest\"\n",
    "              ]    \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The accuracy score achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")\n",
    "\n",
    "#sns.set(rc={'figure.figsize':(20,8)})\n",
    "\n",
    "df = pd.DataFrame({'Algorithm':algorithms, 'Accuracy':scores})\n",
    "sns.set(rc={'figure.figsize':(12,6)})\n",
    "sns.barplot(data=df, x = 'Algorithm', y='Accuracy')\n",
    "plt.ylim(0,100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [\n",
    "          fn_osvm,\n",
    "          fn_sgd,\n",
    "          fn_lof,\n",
    "          fn_env,\n",
    "          fn_iso\n",
    "          ] \n",
    "\n",
    "for i in range(len(algorithms)):\n",
    "    print(\"The false negative rate achieved using \"+algorithms[i]+\" is: \"+str(scores[i])+\" %\")\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12,6)})\n",
    "\n",
    "df = pd.DataFrame({'Algorithm':algorithms, 'False negative rate':scores})\n",
    "sns.barplot(data=df, x = 'Algorithm', y='False negative rate')\n",
    "plt.ylim(0,100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
